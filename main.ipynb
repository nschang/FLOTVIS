{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"yolov4-keras-plastic.ipynb","provenance":[],"collapsed_sections":["NqSHXmHxgRQL","MHaivvzxgCGW","-YxseCS2js4c","RbQcqHvxF8yN","HCHgiQmvfNGu","xLb0GtWdOAZn","aF3hPP_-yxh2","ukLlMbMIZDXF","GIXaFdDoGLxs","bAR6OoGwteMF"],"machine_shape":"hm","mount_file_id":"1JMtM73wn2e_6NhaB6BR_IThM_DMbtoso","authorship_tag":"ABX9TyPTn6IA5xzGpap8el0NFrxi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# FLOTVIS:\n","## a YOLOv4/TF-Keras based floating plastic debris detector\n","\n","This code is designed to run on Google Colab <https://colab.research.google.com/>\n","\n","<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/nschang/FLOTVIS\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","</table>\n"],"metadata":{}},{"cell_type":"markdown","source":["# Define Variables"],"metadata":{"id":"MHaivvzxgCGW"}},{"cell_type":"code","execution_count":null,"source":["# uncomment if using Colab\n","# # mount Google Drive\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# '''\n","# DRIVE_PATH = '/content/drive/MyDrive'\n","# '''\n","# select tensorflow version\n","# %tensorflow_version 1.x"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":19,"source":["# check current path\n","!pwd\n","# ------------------------------------\n","import os\n","# ------------------------------------\n","# format: YYMMDDHHSS\n","TODAY = '2109022300' # change this to current date\n","# ------------------------------------\n","#LAST  = ''\n","SAVE_PATH = 'FLOTV'\n","LOG_PATH = 'train'\n","RESULT_PATH = 'results'\n","DRIVE_PATH = '/content/drive/MyDrive'\n","# ------------------------------------\n","%cd /content/$SAVE_PATH\n","!pwd"],"outputs":[{"output_type":"stream","name":"stdout","text":["/Volumes/Extreme-SSD/thesis/FLOTVIS\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sq_KlELBgqDK","executionInfo":{"status":"ok","timestamp":1630832690175,"user_tz":-120,"elapsed":21,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"ba2b7849-5bc2-4688-b63d-50b89df4fe89"}},{"cell_type":"markdown","source":["# Clone from Github"],"metadata":{"id":"5YJyxoTHf8lc"}},{"cell_type":"code","execution_count":null,"source":["%cd /content/\n","!git clone https://github.com/nschang/FLOTVIS.git"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXfJXZLsUsNa","executionInfo":{"status":"ok","timestamp":1630830755372,"user_tz":-120,"elapsed":4942,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"d7e21f64-b651-4d83-d87a-08fa60f125fe"}},{"cell_type":"code","execution_count":null,"source":["# import dataset\n","# also removes old dataset if present\n","#!rm -rf results train val VOCdevkit/VOC2007/Annotations VOCdevkit/VOC2007/JPEGImages vision_for_anchors.jpg predict.jpg prediction\n","LOCAL_PATH = cwd + '/VOCdevkit/VOC2007'\n","REMOTE_PATH = 'https://dataset.zip'\n","\n","!wget -nc $LOCAL_PATH/dataset.zip $REMOTE_PATH\n","%cd $cwd/VOCdevkit/VOC2007/\n","!unzip dataset.zip\n","!rm -rf __MACOSX dataset.zip"],"outputs":[],"metadata":{"id":"lDMept1wYIn5"}},{"cell_type":"markdown","source":["# Environment Set-up"],"metadata":{"id":"8WQ5SmHoxCTA"}},{"cell_type":"code","execution_count":null,"source":["# install dependencies\n","%cd $cwd\n","!pip install -r $cwd/requirements.txt"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HV0B_HAhzIfE","executionInfo":{"status":"ok","timestamp":1630832702797,"user_tz":-120,"elapsed":5874,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"35c42de6-4569-49a9-80e4-70dade9a9165"}},{"cell_type":"code","execution_count":null,"source":["# show installed environment\n","!pip show tensorflow-estimator\n","!echo '--------'\n","!pip show keras\n","!echo '--------'\n","!pip show h5py\n","!echo '--------'\n","# check tensorflow version and active GPU device\n","import tensorflow as tf\n","print('tensorflow version is ', tf.__version__)\n","tf.test.gpu_device_name() # '/device:GPU:0' means active GPU\n","# get GPU Info\n","# !nvidia-smi"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JfBFxqqYmsnm","executionInfo":{"status":"ok","timestamp":1630832722376,"user_tz":-120,"elapsed":16074,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"8a3cf985-24c6-4b12-8f26-18aeb1aa702f"}},{"cell_type":"markdown","source":["# --- Predict ---"],"metadata":{}},{"cell_type":"markdown","source":["# Predict"],"metadata":{"id":"6fUC86z6tmNG"}},{"cell_type":"code","execution_count":22,"source":["%cd $cwd\n","# get FPS\n","!python3 predict.py --mode='fps'"],"outputs":[{"output_type":"stream","name":"stdout","text":["/Volumes/Extreme-SSD/thesis/FLOTVIS\n","Using TensorFlow backend.\n","/Users/nick/.pyenv/versions/3.6.9/envs/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/Users/nick/.pyenv/versions/3.6.9/envs/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/Users/nick/.pyenv/versions/3.6.9/envs/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/Users/nick/.pyenv/versions/3.6.9/envs/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/Users/nick/.pyenv/versions/3.6.9/envs/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/Users/nick/.pyenv/versions/3.6.9/envs/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","2021-09-18 19:56:11.860705: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n","model_data/trained_weights_stage_1.h5 model, anchors, and classes loaded.\n","Traceback (most recent call last):\n","  File \"predict.py\", line 39, in <module>\n","    yolo = YOLO()\n","  File \"/Volumes/Extreme-SSD/thesis/FLOTVIS/yolo.py\", line 54, in __init__\n","    self.boxes, self.scores, self.classes = self.generate()\n","  File \"/Volumes/Extreme-SSD/thesis/FLOTVIS/yolo.py\", line 127, in generate\n","    score_threshold = self.score, iou_threshold = self.iou, letterbox_image = self.letterbox_image)\n","AttributeError: 'YOLO' object has no attribute 'letterbox_image'\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ACSG85nV-mx","executionInfo":{"status":"ok","timestamp":1630832952913,"user_tz":-120,"elapsed":230559,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"eb4414aa-7a32-438e-b556-c9a4df5b3b0d"}},{"cell_type":"code","execution_count":24,"source":["import os\n","from tqdm import tqdm\n","image_ids1 = os.listdir('./test/')\n","image_ids = [f for f in os.listdir('./test/') if f.endswith(\".jpg\")]\n","print(tqdm(image_ids))\n","print(image_ids1)\n","print(image_ids)"],"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["  0%|          | 0/1 [00:00<?, ?it/s]\n","['.DS_Store', 'test.mp4', 'test.jpg']\n","['test.jpg']\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["%cd $cwd\n","# predict single image\n","#img = input('Input image filename:')\n","!python3 predict.py --mode='image' --img='test/test.jpg'"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["%cd $cwd\n","# predict all images in folder\n","!python3 predict.py --mode='batch' --imgdir='./test/'"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["%cd $cwd\n","# predict video\n","!python3 predict.py --mode='video' --vid='test/test.mp4'"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["%cd $cwd\n","# predict using camera\n","!python3 predict.py --mode='camera'"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# --- Train ---"],"metadata":{}},{"cell_type":"markdown","source":["# Test"],"metadata":{"id":"-YxseCS2js4c"}},{"cell_type":"code","execution_count":null,"source":["# reload all modules before execution\n","%load_ext autoreload\n","%autoreload 2\n","# test\n","%cd $cwd/\n","!python test.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q21ZJ7_q7Dke","executionInfo":{"status":"ok","timestamp":1630722830149,"user_tz":-120,"elapsed":15710,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"90ed325d-f282-460a-98ac-df1fdb32f505"}},{"cell_type":"markdown","source":["# Dataset Check"],"metadata":{"id":"RbQcqHvxF8yN"}},{"cell_type":"code","execution_count":null,"source":["# simple script to evaluate the dataset integrity and consistency\n","\n","# create a new folder Allempty, means to use the xml file as \n","# a reference for image checking, if the image does not have \n","# corresponding xml file, then move it to Allempty folder\n","\n","%cd $cwd/VOCdevkit/VOC2007\n","import os, shutil\n","\n","def checkJpgXml(dir1, dir2, dir3, is_move=True):\n","    \"\"\"\n","    dir1 is the folder where the image is located\n","    dir2 is the folder where the annotation files are located\n","    dir3 is created if the image does not have a corresponding xml file, then the image is put into dir3\n","    is_move is to confirm whether to move or not, otherwise just print\n","    \"\"\"\n","    if not os.path.exists(dir3):\n","        os.mkdir(dir3)\n","    cnt = 0\n","    for file in os.listdir(dir1):\n","        f_name,f_ext = file.split(\".\")\n","        if not os.path.exists(os.path.join(dir2, f_name+\".xml\")):\n","            print(f_name)\n","            if is_move:\n","                cnt += 1\n","                shutil.move(os.path.join(dir1,file), os.path.join(dir3, file))\n","    if cnt > 0:\n","        print(\"There are %d files that do not meet the requirements and have been printed.\"%(cnt))\n","    else:\n","        print(\"All images and corresponding xml files are one-to-one.\")\n","\n","if __name__ == \"__main__\":\n","    dir1 = r\"JPEGImages\"\n","    dir2 = r\"Annotations\"\n","    dir3 = r\"Allempty\"\n","    checkJpgXml(dir1, dir2, dir3, False)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDgaeNnYFmeA","executionInfo":{"status":"ok","timestamp":1630722834402,"user_tz":-120,"elapsed":359,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"970be31f-a4a4-41a1-c3c2-bde792c1281f"}},{"cell_type":"code","execution_count":null,"source":["# number of images\n","!echo 'number of images'; find $cwd/VOCdevkit/VOC2007/JPEGImages -type f | wc -l\n","# number of labels (in .xml format)\n","!echo 'number of labels'; find $cwd/VOCdevkit/VOC2007/Annotations -type f | wc -l"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEgtk-FzrYMu","executionInfo":{"status":"ok","timestamp":1630722835186,"user_tz":-120,"elapsed":14,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"f4bdc62b-b466-41a3-da28-1f58d62ab04f"}},{"cell_type":"code","execution_count":null,"source":["%cd $cwd/VOCdevkit/VOC2007/\n","!python $cwd/VOCdevkit/VOC2007/voc2yolo4.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tP9yQ_3ta6pj","executionInfo":{"status":"ok","timestamp":1630722835187,"user_tz":-120,"elapsed":12,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"c750139f-2e93-497c-8c03-fdad3b04c2ba"}},{"cell_type":"code","execution_count":null,"source":["%cd $cwd/\n","!python voc_annotation.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dRyl1qYZeogO","executionInfo":{"status":"ok","timestamp":1630722835577,"user_tz":-120,"elapsed":398,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"c8f4f92b-48a9-4384-8185-9ec8be95708b"}},{"cell_type":"code","execution_count":null,"source":["# k-means\n","%cd $cwd/\n","!python $cwd/kmeans_for_anchors.py\n","!mv $cwd/model_data/yolo_anchors.txt $cwd/model_data/yolo_anchors.txt.bak\n","!mv $cwd/yolo_anchors.txt $cwd/model_data/yolo_anchors.txt"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G35dnDQVADOh","executionInfo":{"status":"ok","timestamp":1630722836921,"user_tz":-120,"elapsed":1348,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"fc484c15-93f8-443c-db7c-6c670b4477e5"}},{"cell_type":"code","execution_count":null,"source":["# get anchor\n","%cd $cwd/\n","#!python /content/yolov4-keras-2/vision_for_anchors.py\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def sigmoid(x):\n","    s = 1 / (1 + np.exp(-x))\n","    return s\n","\n","# 13x13\n","def yolo_head(feats, anchors, num_classes):\n","    # 3\n","    num_anchors = len(anchors)\n","    # [1, 1, 1, num_anchors, 2]\n","    anchors_tensor = np.reshape(anchors, [1, 1, 1, num_anchors, 2])  / 32\n","\n","    # get x,y grid\n","    # (13,13, 1, 2)\n","    grid_shape = np.shape(feats)[1:3] # height, width\n","    print(grid_shape)\n","    grid_y = np.tile(np.reshape(np.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n","        [1, grid_shape[1], 1, 1])\n","    grid_x = np.tile(np.reshape(np.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n","        [grid_shape[0], 1, 1, 1])\n","    grid = np.concatenate([grid_x, grid_y],-1)\n","    print(np.shape(grid))\n","    # (batch_size,13,13,3,85)\n","    feats = np.reshape(feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n","\n","    # adjust predict val to true val\n","    # box_xy = center of box\n","    # box_wh = width and height of box\n","    box_xy = (sigmoid(feats[..., :2]) + grid)\n","    box_wh = np.exp(feats[..., 2:4]) * anchors_tensor\n","    box_confidence = sigmoid(feats[..., 4:5])\n","    box_class_probs = sigmoid(feats[..., 5:])\n","\n","  \n","    fig = plt.figure()\n","    ax = fig.add_subplot(121)\n","    plt.ylim(-2,15)\n","    plt.xlim(-2,15)\n","    plt.scatter(grid_x,grid_y)\n","    plt.scatter(5,5,c='black')\n","    plt.gca().invert_yaxis()\n","\n","\n","    anchor_left = grid_x - anchors_tensor/2 \n","    anchor_top = grid_y - anchors_tensor/2 \n","    print(np.shape(anchors_tensor))\n","    rect1 = plt.Rectangle([anchor_left[0,5,5,0,0],anchor_top[0,5,5,0,1]],anchors_tensor[0,0,0,0,0],anchors_tensor[0,0,0,0,1],color=\"r\",fill=False)\n","    rect2 = plt.Rectangle([anchor_left[0,5,5,1,0],anchor_top[0,5,5,1,1]],anchors_tensor[0,0,0,1,0],anchors_tensor[0,0,0,1,1],color=\"r\",fill=False)\n","    rect3 = plt.Rectangle([anchor_left[0,5,5,2,0],anchor_top[0,5,5,2,1]],anchors_tensor[0,0,0,2,0],anchors_tensor[0,0,0,2,1],color=\"r\",fill=False)\n","\n","    ax.add_patch(rect1)\n","    ax.add_patch(rect2)\n","    ax.add_patch(rect3)\n","\n","    ax = fig.add_subplot(122)\n","    plt.ylim(-2,15)\n","    plt.xlim(-2,15)\n","    plt.scatter(grid_x,grid_y)\n","    plt.scatter(5,5,c='black')\n","    plt.scatter(box_xy[0,5,5,:,0],box_xy[0,5,5,:,1],c='r')\n","    plt.gca().invert_yaxis()\n","\n","    pre_left = box_xy[...,0] - box_wh[...,0]/2 \n","    pre_top = box_xy[...,1] - box_wh[...,1]/2 \n","\n","    rect1 = plt.Rectangle([pre_left[0,5,5,0],pre_top[0,5,5,0]],box_wh[0,5,5,0,0],box_wh[0,5,5,0,1],color=\"r\",fill=False)\n","    rect2 = plt.Rectangle([pre_left[0,5,5,1],pre_top[0,5,5,1]],box_wh[0,5,5,1,0],box_wh[0,5,5,1,1],color=\"r\",fill=False)\n","    rect3 = plt.Rectangle([pre_left[0,5,5,2],pre_top[0,5,5,2]],box_wh[0,5,5,2,0],box_wh[0,5,5,2,1],color=\"r\",fill=False)\n","\n","    ax.add_patch(rect1)\n","    ax.add_patch(rect2)\n","    ax.add_patch(rect3)\n","\n","    plt.show()\n","    #\n","feat = np.random.normal(0,0.5,[4,13,13,75])\n","anchors = [[142, 110],[192, 243],[459, 401]]\n","yolo_head(feat,anchors,20)\n"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"FfS4TOAr-xYT","executionInfo":{"status":"ok","timestamp":1630722836922,"user_tz":-120,"elapsed":20,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"7bac460d-b642-46cc-dff3-8a3b682bb5cf"}},{"cell_type":"markdown","source":["# Train"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# check tensorflow version and active GPU device\n","import tensorflow as tf\n","print('tensorflow version is ', tf.__version__)\n","tf.test.gpu_device_name() # '/device:GPU:0' means active GPU\n","physical_devices = tf.config.list_physical_devices('GPU')\n","print(\"Num GPUs:\", len(physical_devices))\n","# allow GPU growth\n","# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n","\n"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7bDu1MLzuSJ","executionInfo":{"status":"ok","timestamp":1630618580255,"user_tz":-120,"elapsed":537,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"f591d1ae-4c16-4a6e-9fab-b93704b60d32"}},{"cell_type":"code","execution_count":null,"source":["# Load the TensorBoard notebook extension before training\n","# in case of error, run: pip uninstall tensorboard-plugin-wit\n","%load_ext tensorboard\n","import tensorflow as tf\n","import datetime, os\n","%tensorboard --logdir train #--host localhost --port 8088\n","\n","from tensorboard import notebook\n","notebook.list() # View open TensorBoard instances\n","\n","# Control TensorBoard display. If no port is provided, the most recently launched TensorBoard is used\n","#notebook.display(port=8088, height=1000) "],"outputs":[],"metadata":{"id":"oec1ORpj0gtw"}},{"cell_type":"code","execution_count":null,"source":["# train\n","%cd $cwd\n","!python train.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQDsjtzseyI4","executionInfo":{"status":"ok","timestamp":1630727833178,"user_tz":-120,"elapsed":4938509,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"1c5914af-67c2-4dc9-d159-e4c4a00cb51f"}},{"cell_type":"markdown","source":["# Evaluate"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["%cd $cwd\n","!python get_dr_txt.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNdjnj5L2Ltf","executionInfo":{"status":"ok","timestamp":1630727869006,"user_tz":-120,"elapsed":35856,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"97df2f29-8152-4b0a-e453-4ef1922050f8"}},{"cell_type":"code","execution_count":null,"source":["!python get_gt_txt.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpavLkR32XyH","executionInfo":{"status":"ok","timestamp":1630727869008,"user_tz":-120,"elapsed":23,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"dc985f58-b98e-4ebf-9441-753ea1f05fde"}},{"cell_type":"code","execution_count":null,"source":["!python get_map.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_DNRLlhP2c2y","executionInfo":{"status":"ok","timestamp":1630727914999,"user_tz":-120,"elapsed":46000,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"e34bae11-1aff-42a7-be2e-20538b0b89fd"}}]}