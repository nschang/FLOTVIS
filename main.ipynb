{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"yolov4-keras-plastic.ipynb","provenance":[],"collapsed_sections":["NqSHXmHxgRQL","MHaivvzxgCGW","-YxseCS2js4c","RbQcqHvxF8yN","HCHgiQmvfNGu","xLb0GtWdOAZn","aF3hPP_-yxh2","ukLlMbMIZDXF","GIXaFdDoGLxs","bAR6OoGwteMF"],"machine_shape":"hm","mount_file_id":"1JMtM73wn2e_6NhaB6BR_IThM_DMbtoso","authorship_tag":"ABX9TyPTn6IA5xzGpap8el0NFrxi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# FLOTV:\n","## a YOLOv4/TF-Keras based floating plastic debris detector\n","\n","This code is designed to run on Google Colab <https://colab.research.google.com/>\n","\n","<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/nschang/FLOTV\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","</table>\n"],"metadata":{}},{"cell_type":"markdown","source":["# Define Variables"],"metadata":{"id":"MHaivvzxgCGW"}},{"cell_type":"code","execution_count":null,"source":["# check current path\n","!pwd\n","# ------------------------------------\n","import os\n","# ------------------------------------\n","# format: YYMMDDHHSS\n","TODAY = '2109022300' # change this to current date\n","# ------------------------------------\n","#LAST  = ''\n","SAVE_PATH = 'FLOTV'\n","LOG_PATH = 'train'\n","RESULT_PATH = 'results'\n","DRIVE_PATH = '/content/drive/MyDrive'\n","# ------------------------------------\n","%cd /content/$SAVE_PATH\n","!pwd"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sq_KlELBgqDK","executionInfo":{"status":"ok","timestamp":1630832690175,"user_tz":-120,"elapsed":21,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"ba2b7849-5bc2-4688-b63d-50b89df4fe89"}},{"cell_type":"code","execution_count":null,"source":["# select dataset to import\n","DATASET = 'base-1227.zip'\n","#DATASET = 'extra-TACO-16.zip'\n","#DATASET = 'extra-lieshout-526.zip'\n","#DATASET = 'extra-sample-testing-278.zip'\n","#DATASET = 'extra-trashnet-482.zip'\n","#DATASET = 'extra-HAIDA-509.zip'\n","# ------------------------------------\n","DATASET_DRIVE_PATH = '/content/drive/MyDrive/dataset'\n","DATASET_PATH = DATASET_DRIVE_PATH + '/' + DATASET"],"outputs":[],"metadata":{"id":"kTIMeDbGYZLe","executionInfo":{"status":"ok","timestamp":1630832690179,"user_tz":-120,"elapsed":16,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}}}},{"cell_type":"markdown","source":["# Download and Clone"],"metadata":{"id":"5YJyxoTHf8lc"}},{"cell_type":"code","execution_count":null,"source":["%cd /content/\n","!git clone https://nschang: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@github.com/nschang/FLOTV.git"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXfJXZLsUsNa","executionInfo":{"status":"ok","timestamp":1630830755372,"user_tz":-120,"elapsed":4942,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"d7e21f64-b651-4d83-d87a-08fa60f125fe"}},{"cell_type":"code","execution_count":null,"source":["# import dataset\n","# also removes old dataset if present\n","#!rm -rf /content/FLOTV/results /content/FLOTV/train /content/FLOTV/val /content/FLOTV/VOCdevkit/VOC2007/Annotations /content/FLOTV/VOCdevkit/VOC2007/JPEGImages /content/FLOTV/vision_for_anchors.jpg /content/FLOTV/predict.jpg /content/FLOTV/prediction\n","!rsync -hvrPt --info=progress2 $DATASET_PATH /content/FLOTV/VOCdevkit/VOC2007/\n","%cd /content/FLOTV/VOCdevkit/VOC2007/\n","!unzip $DATASET\n","!rm -rf __MACOSX $DATASET"],"outputs":[],"metadata":{"id":"lDMept1wYIn5"}},{"cell_type":"markdown","source":["# Environment Set-up"],"metadata":{"id":"8WQ5SmHoxCTA"}},{"cell_type":"code","execution_count":null,"source":["# get GPU Info\n","!nvidia-smi"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JvCGGsJMloHr","executionInfo":{"status":"ok","timestamp":1630832696932,"user_tz":-120,"elapsed":339,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"f38ca1ea-e89d-473f-90ec-c75640a1b2ff"}},{"cell_type":"code","execution_count":null,"source":["# select tenforflow version 1.x\n","%tensorflow_version 1.x"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IFLdPaCbzH51","executionInfo":{"status":"ok","timestamp":1630832696934,"user_tz":-120,"elapsed":12,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"22ea2ffd-f250-4abb-c2bc-d27e251efa68"}},{"cell_type":"code","execution_count":null,"source":["# install dependencies\n","%cd /content/$SAVE_PATH\n","!pip install -r /content/$SAVE_PATH/requirements.txt #-qqq\n","# manually restart runtime once"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HV0B_HAhzIfE","executionInfo":{"status":"ok","timestamp":1630832702797,"user_tz":-120,"elapsed":5874,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"35c42de6-4569-49a9-80e4-70dade9a9165"}},{"cell_type":"code","execution_count":null,"source":["# check tensorflow version\n","import tensorflow as tf\n","print('tensorflow version is ', tf.__version__)\n","# '/device:GPU:0' means active GPU\n","tf.test.gpu_device_name()"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"MjflaD7EzNQe","executionInfo":{"status":"ok","timestamp":1630832706312,"user_tz":-120,"elapsed":3519,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"4ee94dd2-47b1-4f33-cc8e-0e73c34b58d6"}},{"cell_type":"code","execution_count":null,"source":["# show installed environment\n","!pip show tensorflow-estimator\n","!echo '--------'\n","!pip show keras\n","!echo '--------'\n","!pip show h5py\n","%cd /content/$SAVE_PATH"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JfBFxqqYmsnm","executionInfo":{"status":"ok","timestamp":1630832722376,"user_tz":-120,"elapsed":16074,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"8a3cf985-24c6-4b12-8f26-18aeb1aa702f"}},{"cell_type":"markdown","source":["# Test"],"metadata":{"id":"-YxseCS2js4c"}},{"cell_type":"code","execution_count":null,"source":["# reload all modules before execution\n","%load_ext autoreload\n","%autoreload 2\n","%cd /content/$SAVE_PATH/\n","!python test.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q21ZJ7_q7Dke","executionInfo":{"status":"ok","timestamp":1630722830149,"user_tz":-120,"elapsed":15710,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"90ed325d-f282-460a-98ac-df1fdb32f505"}},{"cell_type":"markdown","source":["# Dataset Check\n","## A simple script to evaluate the consistency\n","create a new folder Allempty, means to use the xml file as a reference for image checking, if the image does not exist corresponding xml file, then the image will be moved to Allempty folder."],"metadata":{"id":"RbQcqHvxF8yN"}},{"cell_type":"code","execution_count":null,"source":["%cd /content/$SAVE_PATH/VOCdevkit/VOC2007\n","import os, shutil\n","\n","def checkJpgXml(dir1, dir2, dir3, is_move=True):\n","    \"\"\"\n","    dir1 is the folder where the image is located\n","    dir2 is the folder where the annotation files are located\n","    dir3 is created if the image does not have a corresponding xml file, then the image is put into dir3\n","    is_move is to confirm whether to move or not, otherwise just print\n","    \"\"\"\n","    if not os.path.exists(dir3):\n","        os.mkdir(dir3)\n","    cnt = 0\n","    for file in os.listdir(dir1):\n","        f_name,f_ext = file.split(\".\")\n","        if not os.path.exists(os.path.join(dir2, f_name+\".xml\")):\n","            print(f_name)\n","            if is_move:\n","                cnt += 1\n","                shutil.move(os.path.join(dir1,file), os.path.join(dir3, file))\n","    if cnt > 0:\n","        print(\"There are %d files that do not meet the requirements and have been printed.\"%(cnt))\n","    else:\n","        print(\"All images and corresponding xml files are one-to-one.\")\n","\n","if __name__ == \"__main__\":\n","    dir1 = r\"JPEGImages\"\n","    dir2 = r\"Annotations\"\n","    dir3 = r\"Allempty\"\n","    checkJpgXml(dir1, dir2, dir3, False)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDgaeNnYFmeA","executionInfo":{"status":"ok","timestamp":1630722834402,"user_tz":-120,"elapsed":359,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"970be31f-a4a4-41a1-c3c2-bde792c1281f"}},{"cell_type":"code","execution_count":null,"source":["# number of images\n","!echo 'number of images'; find /content/$SAVE_PATH/VOCdevkit/VOC2007/JPEGImages -type f | wc -l\n","# number of labels (in .xml format)\n","!echo 'number of labels'; find /content/$SAVE_PATH/VOCdevkit/VOC2007/Annotations -type f | wc -l"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEgtk-FzrYMu","executionInfo":{"status":"ok","timestamp":1630722835186,"user_tz":-120,"elapsed":14,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"f4bdc62b-b466-41a3-da28-1f58d62ab04f"}},{"cell_type":"code","execution_count":null,"source":["%cd /content/$SAVE_PATH/VOCdevkit/VOC2007/\n","!python /content/$SAVE_PATH/VOCdevkit/VOC2007/voc2yolo4.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tP9yQ_3ta6pj","executionInfo":{"status":"ok","timestamp":1630722835187,"user_tz":-120,"elapsed":12,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"c750139f-2e93-497c-8c03-fdad3b04c2ba"}},{"cell_type":"code","execution_count":null,"source":["%cd /content/$SAVE_PATH/\n","!python voc_annotation.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dRyl1qYZeogO","executionInfo":{"status":"ok","timestamp":1630722835577,"user_tz":-120,"elapsed":398,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"c8f4f92b-48a9-4384-8185-9ec8be95708b"}},{"cell_type":"code","execution_count":null,"source":["%cd /content/$SAVE_PATH/\n","!python /content/$SAVE_PATH/kmeans_for_anchors.py\n","!rm /content/FLOTV/model_data/yolo_anchors.txt\n","!mv /content/FLOTV/yolo_anchors.txt /content/FLOTV/model_data/yolo_anchors.txt"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G35dnDQVADOh","executionInfo":{"status":"ok","timestamp":1630722836921,"user_tz":-120,"elapsed":1348,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"fc484c15-93f8-443c-db7c-6c670b4477e5"}},{"cell_type":"code","execution_count":null,"source":["%cd /content/$SAVE_PATH/\n","#!python /content/yolov4-keras-2/vision_for_anchors.py\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def sigmoid(x):\n","    s = 1 / (1 + np.exp(-x))\n","    return s\n","\n","# 13x13\n","def yolo_head(feats, anchors, num_classes):\n","    # 3\n","    num_anchors = len(anchors)\n","    # [1, 1, 1, num_anchors, 2]\n","    anchors_tensor = np.reshape(anchors, [1, 1, 1, num_anchors, 2])  / 32\n","\n","    # get x,y grid\n","    # (13,13, 1, 2)\n","    grid_shape = np.shape(feats)[1:3] # height, width\n","    print(grid_shape)\n","    grid_y = np.tile(np.reshape(np.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n","        [1, grid_shape[1], 1, 1])\n","    grid_x = np.tile(np.reshape(np.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n","        [grid_shape[0], 1, 1, 1])\n","    grid = np.concatenate([grid_x, grid_y],-1)\n","    print(np.shape(grid))\n","    # (batch_size,13,13,3,85)\n","    feats = np.reshape(feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n","\n","    # adjust predict val to true val\n","    # box_xy = center of box\n","    # box_wh = width and height of box\n","    box_xy = (sigmoid(feats[..., :2]) + grid)\n","    box_wh = np.exp(feats[..., 2:4]) * anchors_tensor\n","    box_confidence = sigmoid(feats[..., 4:5])\n","    box_class_probs = sigmoid(feats[..., 5:])\n","\n","  \n","    fig = plt.figure()\n","    ax = fig.add_subplot(121)\n","    plt.ylim(-2,15)\n","    plt.xlim(-2,15)\n","    plt.scatter(grid_x,grid_y)\n","    plt.scatter(5,5,c='black')\n","    plt.gca().invert_yaxis()\n","\n","\n","    anchor_left = grid_x - anchors_tensor/2 \n","    anchor_top = grid_y - anchors_tensor/2 \n","    print(np.shape(anchors_tensor))\n","    rect1 = plt.Rectangle([anchor_left[0,5,5,0,0],anchor_top[0,5,5,0,1]],anchors_tensor[0,0,0,0,0],anchors_tensor[0,0,0,0,1],color=\"r\",fill=False)\n","    rect2 = plt.Rectangle([anchor_left[0,5,5,1,0],anchor_top[0,5,5,1,1]],anchors_tensor[0,0,0,1,0],anchors_tensor[0,0,0,1,1],color=\"r\",fill=False)\n","    rect3 = plt.Rectangle([anchor_left[0,5,5,2,0],anchor_top[0,5,5,2,1]],anchors_tensor[0,0,0,2,0],anchors_tensor[0,0,0,2,1],color=\"r\",fill=False)\n","\n","    ax.add_patch(rect1)\n","    ax.add_patch(rect2)\n","    ax.add_patch(rect3)\n","\n","    ax = fig.add_subplot(122)\n","    plt.ylim(-2,15)\n","    plt.xlim(-2,15)\n","    plt.scatter(grid_x,grid_y)\n","    plt.scatter(5,5,c='black')\n","    plt.scatter(box_xy[0,5,5,:,0],box_xy[0,5,5,:,1],c='r')\n","    plt.gca().invert_yaxis()\n","\n","    pre_left = box_xy[...,0] - box_wh[...,0]/2 \n","    pre_top = box_xy[...,1] - box_wh[...,1]/2 \n","\n","    rect1 = plt.Rectangle([pre_left[0,5,5,0],pre_top[0,5,5,0]],box_wh[0,5,5,0,0],box_wh[0,5,5,0,1],color=\"r\",fill=False)\n","    rect2 = plt.Rectangle([pre_left[0,5,5,1],pre_top[0,5,5,1]],box_wh[0,5,5,1,0],box_wh[0,5,5,1,1],color=\"r\",fill=False)\n","    rect3 = plt.Rectangle([pre_left[0,5,5,2],pre_top[0,5,5,2]],box_wh[0,5,5,2,0],box_wh[0,5,5,2,1],color=\"r\",fill=False)\n","\n","    ax.add_patch(rect1)\n","    ax.add_patch(rect2)\n","    ax.add_patch(rect3)\n","\n","    plt.show()\n","    #\n","feat = np.random.normal(0,0.5,[4,13,13,75])\n","anchors = [[142, 110],[192, 243],[459, 401]]\n","yolo_head(feat,anchors,20)\n"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"FfS4TOAr-xYT","executionInfo":{"status":"ok","timestamp":1630722836922,"user_tz":-120,"elapsed":20,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"7bac460d-b642-46cc-dff3-8a3b682bb5cf"}},{"cell_type":"markdown","source":["# --------------- Train ---------------"],"metadata":{"id":"JaH6hl3lB_Y3"}},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"HCHgiQmvfNGu"}},{"cell_type":"code","execution_count":null,"source":["# enable GPU memory growth\n","# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n","import tensorflow as tf\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True"],"outputs":[],"metadata":{"id":"gPLKu_nthO1I","executionInfo":{"status":"ok","timestamp":1630722838838,"user_tz":-120,"elapsed":3,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}}}},{"cell_type":"code","execution_count":null,"source":["import tensorflow\n","tensorflow.__version__"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"mGT3aT6XnCaz","executionInfo":{"status":"ok","timestamp":1630722842952,"user_tz":-120,"elapsed":777,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"9c9b0a35-66c8-4f5d-9be0-e3d2dd53a4cc"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7bDu1MLzuSJ","executionInfo":{"status":"ok","timestamp":1630618580255,"user_tz":-120,"elapsed":537,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"f591d1ae-4c16-4a6e-9fab-b93704b60d32"}},{"cell_type":"code","execution_count":null,"source":["# Load the TensorBoard notebook extension\n","from tensorboard import notebook\n","notebook.list() # View open TensorBoard instances\n","# in case of error, run: pip uninstall tensorboard-plugin-wit\n","!pip uninstall tensorboard-plugin-wit -y\n","%load_ext tensorboard\n","import tensorflow as tf\n","import datetime, os\n","%tensorboard --logdir train\n","#%tensorboard --logdir train --host localhost --port 8088\n","# Control TensorBoard display. If no port is provided, \n","# the most recently launched TensorBoard is used\n","#notebook.display(port=8088, height=1000) "],"outputs":[],"metadata":{"id":"oec1ORpj0gtw"}},{"cell_type":"code","execution_count":null,"source":["%cd /content/$SAVE_PATH\n","!python train.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQDsjtzseyI4","executionInfo":{"status":"ok","timestamp":1630727833178,"user_tz":-120,"elapsed":4938509,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"1c5914af-67c2-4dc9-d159-e4c4a00cb51f"}},{"cell_type":"code","execution_count":null,"source":["#!mkdir /content/yolov4-keras-2/train/\n","#!cp -r /content/drive/MyDrive/yolov4-keras-2/train-2108281200/loss_2021_08_25_10_22_13 /content/yolov4-keras-2/train1/\n","#!cp /content/drive/MyDrive/yolov4-keras-2/train-2108281200/trained_weights_stage_1.h5 /content/yolov4-keras-2/train1/"],"outputs":[],"metadata":{"id":"BlzdYF7kgg1B","executionInfo":{"status":"ok","timestamp":1630727833180,"user_tz":-120,"elapsed":40,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}}}},{"cell_type":"code","execution_count":null,"source":["%cd /content/$SAVE_PATH\n","!python get_dr_txt.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNdjnj5L2Ltf","executionInfo":{"status":"ok","timestamp":1630727869006,"user_tz":-120,"elapsed":35856,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"97df2f29-8152-4b0a-e453-4ef1922050f8"}},{"cell_type":"code","execution_count":null,"source":["!python get_gt_txt.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpavLkR32XyH","executionInfo":{"status":"ok","timestamp":1630727869008,"user_tz":-120,"elapsed":23,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"dc985f58-b98e-4ebf-9441-753ea1f05fde"}},{"cell_type":"code","execution_count":null,"source":["!python get_map.py"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_DNRLlhP2c2y","executionInfo":{"status":"ok","timestamp":1630727914999,"user_tz":-120,"elapsed":46000,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"e34bae11-1aff-42a7-be2e-20538b0b89fd"}},{"cell_type":"markdown","source":["# -------------- Predict --------------"],"metadata":{"id":"B4PfI6C4CgXm"}},{"cell_type":"markdown","source":["# Predict"],"metadata":{"id":"6fUC86z6tmNG"}},{"cell_type":"code","execution_count":null,"source":["%cd /content/$SAVE_PATH/\n","#img = input('Input image filename:')\n","!python predict.py --mode='predict' --imgpath='test8'\n","!python predict.py --mode='predict' --imgpath='test7'\n","!python predict.py --mode='predict' --imgpath='test6'\n","!python predict.py --mode='predict' --imgpath='test5'\n","!python predict.py --mode='predict' --imgpath='test4'\n","!python predict.py --mode='predict' --imgpath='test3'\n","!python predict.py --mode='predict' --imgpath='test2'\n","!python predict.py --mode='predict' --imgpath='test1'"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ACSG85nV-mx","executionInfo":{"status":"ok","timestamp":1630832952913,"user_tz":-120,"elapsed":230559,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"}},"outputId":"eb4414aa-7a32-438e-b556-c9a4df5b3b0d"}},{"cell_type":"markdown","source":["# -------------- Backup --------------"],"metadata":{"id":"MbNzFwEbCJvp"}},{"cell_type":"markdown","source":["# -------------- Utilities --------------"],"metadata":{"id":"Ah_3kgFkBWwB"}},{"cell_type":"markdown","source":["# Get Weights"],"metadata":{"id":"xLb0GtWdOAZn"}},{"cell_type":"code","execution_count":null,"source":["%cd /content\n","!git clone https://github.com/david8862/keras-YOLOv3-model-set.git\n","%cd /content/keras-YOLOv3-model-set/weights\n","#!wget -O weights/darknet53.conv.74.weights https://pjreddie.com/media/files/darknet53.conv.74\n","#!wget -O weights/darknet19_448.conv.23.weights https://pjreddie.com/media/files/darknet19_448.conv.23\n","#!wget -O weights/yolov3.weights https://pjreddie.com/media/files/yolov3.weights\n","#!wget -O weights/yolov3-tiny.weights https://pjreddie.com/media/files/yolov3-tiny.weights\n","#!wget -O weights/yolov3-spp.weights https://pjreddie.com/media/files/yolov3-spp.weights\n","#!wget -O weights/yolov2.weights http://pjreddie.com/media/files/yolo.weights\n","#!wget -O weights/yolov2-voc.weights http://pjreddie.com/media/files/yolo-voc.weights\n","#!wget -O weights/yolov2-tiny.weights https://pjreddie.com/media/files/yolov2-tiny.weights\n","#!wget -O weights/yolov2-tiny-voc.weights https://pjreddie.com/media/files/yolov2-tiny-voc.weights\n","\n","### manually download csdarknet53-omega_final.weights from https://drive.google.com/open?id=18jCwaL4SJ-jOvXrZNGHJ5yz44g9zi8Hm\n","#!wget -nc weights/yolov4.weights https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n","\n","#!python tools/model_converter/convert.py cfg/yolov3.cfg weights/yolov3.weights weights/yolov3.h5\n","#!python tools/model_converter/convert.py cfg/yolov3-tiny.cfg weights/yolov3-tiny.weights weights/yolov3-tiny.h5\n","#!python tools/model_converter/convert.py cfg/yolov3-spp.cfg weights/yolov3-spp.weights weights/yolov3-spp.h5\n","#!python tools/model_converter/convert.py cfg/yolov2.cfg weights/yolov2.weights weights/yolov2.h5\n","#!python tools/model_converter/convert.py cfg/yolov2-voc.cfg weights/yolov2-voc.weights weights/yolov2-voc.h5\n","#!python tools/model_converter/convert.py cfg/yolov2-tiny.cfg weights/yolov2-tiny.weights weights/yolov2-tiny.h5\n","#!python tools/model_converter/convert.py cfg/yolov2-tiny-voc.cfg weights/yolov2-tiny-voc.weights weights/yolov2-tiny-voc.h5\n","#!python tools/model_converter/convert.py cfg/darknet53.cfg weights/darknet53.conv.74.weights weights/darknet53.h5\n","#!python tools/model_converter/convert.py cfg/darknet19_448_body.cfg weights/darknet19_448.conv.23.weights weights/darknet19.h5\n","\n","##!python tools/model_converter/convert.py cfg/csdarknet53-omega.cfg weights/csdarknet53-omega_final.weights weights/cspdarknet53.h5\n","\n","### make sure to reorder output tensors for YOLOv4 cfg and weights file\n","#!python tools/model_converter/convert.py --yolo4_reorder cfg/yolov4.cfg weights/yolov4.weights weights/yolov4.h5\n","\n","### Scaled YOLOv4\n","### manually download yolov4-csp.weights from https://drive.google.com/file/d/1NQwz47cW0NUgy7L3_xOKaNEfLoQuq3EL/view?usp=sharing\n","!wget -nc https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-csp.cfg\n","!wget -nc https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-csp.weights\n","%cd ..\n","!python tools/model_converter/convert.py --yolo4_reorder cfg/yolov4-csp_fixed.cfg weights/yolov4-csp.weights weights/scaled-yolov4-csp.h5\n","!mv weights/scaled-yolov4-csp.h5 /content/yolov4-keras-2/model_data/scaled-yolov4-csp.h5\n","%cd /content/yolov4-keras-2/model_data/\n","\n","### Yolo-Fastest\n","#!wget -O weights/yolo-fastest.weights https://github.com/dog-qiuqiu/Yolo-Fastest/raw/master/ModelZoo/yolo-fastest-1.0_coco/yolo-fastest.weights\n","#!wget -O weights/yolo-fastest-xl.weights https://github.com/dog-qiuqiu/Yolo-Fastest/raw/master/ModelZoo/yolo-fastest-1.0_coco/yolo-fastest-xl.weights\n","\n","#!python tools/model_converter/convert.py cfg/yolo-fastest.cfg weights/yolo-fastest.weights weights/yolo-fastest.h5\n","#!python tools/model_converter/convert.py cfg/yolo-fastest-xl.cfg weights/yolo-fastest-xl.weights weights/yolo-fastest-xl.h5\n","\n","#!python yolo.py --image\n","#!python yolo.py --input=<your video file>\n"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"efCy71zzJUQD","executionInfo":{"elapsed":138478,"status":"ok","timestamp":1630164775602,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"},"user_tz":-120},"outputId":"6e61eda0-7d64-4bfc-8bbe-f0ff9ceaf490"}},{"cell_type":"markdown","source":["# Secondary Dataset formatting: CSV-XML"],"metadata":{"id":"aF3hPP_-yxh2"}},{"cell_type":"code","execution_count":null,"source":["# CSV to XML\n","from collections import defaultdict\n","import os\n","import csv\n","\n","from xml.etree.ElementTree import parse, Element, SubElement, ElementTree\n","import xml.etree.ElementTree as ET\n","\n","save_root2 = \"xmls\"\n","\n","if not os.path.exists(save_root2):\n","  os.mkdir(save_root2)\n","\n","\n","def write_xml(folder, filename, bbox_list):\n","  root = Element('annotation')\n","  SubElement(root, 'folder').text = folder\n","  SubElement(root, 'filename').text = filename\n","  SubElement(root, 'path').text = './images' +  filename\n","  source = SubElement(root, 'source')\n","  SubElement(source, 'database').text = 'Unknown'\n","\n","\n","  # Details from first entry\n","  e_filename, e_width, e_height, e_class_name, e_xmin, e_ymin, e_xmax, e_ymax = bbox_list[0]\n","  \n","  size = SubElement(root, 'size')\n","  SubElement(size, 'width').text = e_width\n","  SubElement(size, 'height').text = e_height\n","  SubElement(size, 'depth').text = '3'\n","\n","  SubElement(root, 'segmented').text = '0'\n","\n","  for entry in bbox_list:\n","    e_class_name, e_filename, e_height, e_width, e_xmax, e_xmin, e_ymax, e_ymin = entry\n","    \n","    obj = SubElement(root, 'object')\n","    SubElement(obj, 'name').text = e_class_name\n","    SubElement(obj, 'pose').text = 'Unspecified'\n","    SubElement(obj, 'truncated').text = '0'\n","    SubElement(obj, 'difficult').text = '0'\n","\n","    bbox = SubElement(obj, 'bndbox')\n","    SubElement(bbox, 'xmax').text = e_xmax\n","    SubElement(bbox, 'xmin').text = e_xmin\n","    SubElement(bbox, 'ymax').text = e_ymax\n","    SubElement(bbox, 'ymin').text = e_ymin\n","\n","  #indent(root)\n","  tree = ElementTree(root)\n","  \n","  xml_filename = os.path.join('.', folder, os.path.splitext(filename)[0] + '.xml')\n","  tree.write(xml_filename)\n","  \n","\n","entries_by_filename = defaultdict(list)\n","\n","# change filename (.csv) below\n","\n","with open('train_labels.csv', 'r', encoding='utf-8') as f_input_csv:\n","  csv_input = csv.reader(f_input_csv)\n","  header = next(csv_input)\n","\n","  for row in csv_input:\n","    class_name, filename, height, width, xmax, xmin, ymax, ymin = row\n","\n","    if class_name == \"plastic\":\n","      entries_by_filename[filename].append(row)\n","\n","for filename, entries in entries_by_filename.items():\n","  print(filename, len(entries))\n","  write_xml(save_root2, filename, entries)"],"outputs":[],"metadata":{"id":"siVCFNPZPLYH"}},{"cell_type":"code","execution_count":null,"source":["!zip -r xmls.zip xmls/*"],"outputs":[],"metadata":{"id":"1blt9p4aYkIU"}},{"cell_type":"code","execution_count":null,"source":["%cd /content/yolov4-keras-2/VOCdevkit/VOC2007\n","#!cp /content/drive/MyDrive/yolov4-keras-2/yolov4-keras-2-2108232330/2510.zip\n","#!rm -rf JPEGImages/* Annotations/* new old _MACOSX\n","#!unzip 2510.zip\n","#!mv xml/* Annotations\n","#!mv img/* JPEGImages \n","!rm 2510.zip"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZjbMyTzVupu","executionInfo":{"elapsed":373,"status":"ok","timestamp":1629879085367,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"},"user_tz":-120},"outputId":"54fb59de-cff8-49a8-c42f-a4ac6df609dd"}},{"cell_type":"markdown","source":["# Image Manipulation and Processing in Python"],"metadata":{"id":"ukLlMbMIZDXF"}},{"cell_type":"markdown","source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/load_data/images\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/load_data/images.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","</table>"],"metadata":{"id":"GpX2NMUNBkYz"}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\n","import pandas as pd\n","import cv2 as cv \n","from google.colab.patches import cv2_imshow # for image display\n","from skimage import io\n","from PIL import Image \n","import matplotlib.pylab as plt"],"outputs":[],"metadata":{"id":"wfONd7i2ZCpM"}},{"cell_type":"code","execution_count":null,"source":["%cd /content/$SAVE_PATH/\n","#img=('img/test4.jpg')"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6UpVF22ZYh_","executionInfo":{"elapsed":377,"status":"ok","timestamp":1629732476651,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"},"user_tz":-120},"outputId":"a4d43e0e-ad4f-4165-fabe-2e481edcf03f"}},{"cell_type":"code","execution_count":null,"source":["gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n","cv2_imshow(gray_image)"],"outputs":[],"metadata":{"id":"8BeNkjZ6Zcdl"}},{"cell_type":"code","execution_count":null,"source":["plt.contour(gray_image, origin = \"image\")\n","# Set threshold for the countour detection\n","ret, thresh = cv.threshold(gray_image,150,255,0)\n","im2, contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n","cv.drawContours(image, contours, -1, (0, 255, 0), 3)\n","plt.imshow(image)\n","plt.contour()"],"outputs":[],"metadata":{"id":"tUFBdQkIZirk"}},{"cell_type":"code","execution_count":null,"source":["# Fourier Transform of Gray Images\n","# Blur the grayscale image by a Guassian filter with kernel size of 10\n","imBlur = cv.blur(gray_image,(5,5))\n","# Transform the image to frequency domain\n","f = np.fft.fft2(imBlur)\n","# Bring the zero-frequency component to the center\n","fshift = np.fft.fftshift(f)\n","magnitude_spectrum = 30*np.log(np.abs(fshift))\n","\n","plt.subplot(121),plt.imshow(imBlur, cmap = 'gray')\n","plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n","plt.subplot(122),plt.imshow(magnitude_spectrum, cmap = 'gray')\n","plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n","plt.show()"],"outputs":[],"metadata":{"id":"YbVsjnAkZtJg"}},{"cell_type":"code","execution_count":null,"source":["# Finding Edges by Highpass Filtering in FFT\n","rows, cols = imBlur.shape\n","crow,ccol = round(rows/2) , round(cols/2)\n","# remove low frequencies with a rectangle size of 10\n","fshift[crow-10:crow+10, ccol-10:ccol+10] = 0\n","f_ishift = np.fft.ifftshift(fshift)\n","img_back = np.fft.ifft2(f_ishift)\n","img_back = np.abs(img_back)\n","\n","plt.figure(figsize=([20, 20]))\n","plt.subplot(131),plt.imshow(imBlur, cmap = 'gray')\n","plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n","plt.subplot(132),plt.imshow(img_back, cmap = 'gray')\n","plt.title('Image after HPF'), plt.xticks([]), plt.yticks([])\n","plt.subplot(133),plt.imshow(img_back)\n","plt.title('Result in JET'), plt.xticks([]), plt.yticks([])\n","plt.show()"],"outputs":[],"metadata":{"id":"nXDD6znHZy4p"}},{"cell_type":"markdown","source":["# Advanced GPU Management"],"metadata":{"id":"GIXaFdDoGLxs"}},{"cell_type":"markdown","source":["The GPU should have 12GB of memory by default. This makes sure that current GPU utilization is zero."],"metadata":{"id":"ZOBXcr-NGSCF"}},{"cell_type":"code","execution_count":null,"source":["import tensorflow as tf\n","physical_devices = tf.config.list_physical_devices('GPU')\n","print(\"Num GPUs:\", len(physical_devices))"],"outputs":[],"metadata":{"id":"MQzBCsQKqmTf"}},{"cell_type":"code","execution_count":null,"source":["!pip install psutil\n","!pip install gputil"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RFyEy2k5ZLEm","executionInfo":{"elapsed":5567,"status":"ok","timestamp":1630182246614,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"},"user_tz":-120},"outputId":"ca064c91-8e34-4639-9221-a0a096989308"}},{"cell_type":"code","execution_count":null,"source":["# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm() "],"outputs":[],"metadata":{"id":"NDXiFYaRGKx0"}},{"cell_type":"code","execution_count":null,"source":["# mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"outputs":[],"metadata":{"id":"m6dGsX6qGnLy"}},{"cell_type":"markdown","source":["This creates a new .h5 file with placeholders for training. \n","\n","HDF5 (aka H5) is a memory mapped file formats. The Python package h5py makes it easy to store and manipulate existing data in the form of NumPy arrays. This makes reading data on Colab faster, and will accelerate the training.\n"],"metadata":{"id":"k8hmjaF2HO44"}},{"cell_type":"code","execution_count":null,"source":["import h5py\n","from PIL import Image\n","\n","fileName = 'data.h5'\n","numOfSamples = 10000\n","with h5py.File(fileName, \"w\") as out:\n","  out.create_dataset(\"X_train\",(numOfSamples,256,256,3),dtype='u1')\n","  out.create_dataset(\"Y_train\",(numOfSamples,1,1),dtype='u1')      \n","  out.create_dataset(\"X_dev\",(numOfSamples,256,256,3),dtype='u1')\n","  out.create_dataset(\"Y_dev\",(numOfSamples,1,1),dtype='u1')      \n","  out.create_dataset(\"X_test\",(numOfSamples,256,256,3),dtype='u1')\n","  out.create_dataset(\"Y_test\",(numOfSamples,1,1),dtype='u1')   "],"outputs":[],"metadata":{"id":"VvMk2TqlHOZp"}},{"cell_type":"markdown","source":["load your data into these placeholders in a Python dictionary style. Here we load images to our X_train placeholder."],"metadata":{"id":"JX7WK6-bH0WM"}},{"cell_type":"code","execution_count":null,"source":["with h5py.File(fileName, \"a\") as out:\n","   img = Image.open(\"X_train_1.jpg\")      # X_train_1.jpg is 256 x 256 RGB image\n","   out['X_train'] = numpy.asarray(img)"],"outputs":[],"metadata":{"id":"Xe5r9O7THxpM"}},{"cell_type":"markdown","source":["For PyTorch (not relevant here but good to know), you will have to write your own .h5 Dataset that will be used by PyTorch DataLoader."],"metadata":{"id":"P3BpKkrwH-Gl"}},{"cell_type":"code","execution_count":null,"source":["import torch\n","import numpy as np\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","from PIL import Image\n","import h5py\n"," \n","class dataset_h5(torch.utils.data.Dataset):\n","    def __init__(self, in_file, transform=None):\n","        super(dataset_h5, self).__init__()\n"," \n","        self.file = h5py.File(in_file, 'r')\n","        self.transform = transform\n"," \n","    def __getitem__(self, index):\n","        x = self.file['X_train'][index, ...]\n","        y = self.file['Y_train'][index, ...]\n","        \n","        # Preprocessing each image\n","        if self.transform is not None:\n","            x = self.transform(x)        \n","        \n","        return (x, y), index\n"," \n","    def __len__(self):\n","        return self.file['X_train'].shape[0]\n","\n","dataset = dataset_h5(\"PATH_TO_YOUR_.h5_FILE\",transform=transform)\n","dataloader = torch.utils.data.DataLoader(\n","        dataset, batch_size=8,\n","        drop_last=True, shuffle=bshuffle, num_workers=1)"],"outputs":[],"metadata":{"id":"FtI_jcDAH9H7"}},{"cell_type":"markdown","source":["# cycle through folder"],"metadata":{"id":"bAR6OoGwteMF"}},{"cell_type":"code","execution_count":null,"source":["# cycle through folder 1\n","import os\n","img_path = \"/content/yolov4-keras-2/img\"\n","included_extensions = ['jpg','png', 'gif']\n","file_names = [fn for fn in os.listdir(img_path)\n","              if any(fn.endswith(ext) for ext in included_extensions)]\n","print(file_names)\n","\n","# cycle through folder 2\n","import os\n","%cd /content/\n","os.listdir('/content/yolov4-keras-2/img')\n","for f in os.listdir('/content/yolov4-keras-2/img'):\n","    name, ext = os.path.splitext(f)\n","    if ext == '.img':\n","        print(name)"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lm-YOBmbtawy","executionInfo":{"elapsed":23,"status":"ok","timestamp":1630186698781,"user":{"displayName":"user4856","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjGXgwWDSyceF9cChEBnStb3nIaSSfSUg9KMb6XNw=s64","userId":"00128029891547034217"},"user_tz":-120},"outputId":"c813e439-fe9e-42c4-cf0e-d9ec72f5055e"}},{"cell_type":"markdown","source":["# Commandline Upload/Download"],"metadata":{"id":"w4GXODbwB30p"}},{"cell_type":"code","execution_count":null,"source":["# upload\n","from google.colab import files\n","files.upload()"],"outputs":[],"metadata":{"id":"XFuWuCbdBsem"}},{"cell_type":"code","execution_count":null,"source":["# download\n","from google.colab import files\n","files.download('/content/yolov4-keras-2/requirements.txt')"],"outputs":[],"metadata":{"id":"RW0R6augDEA2"}}]}