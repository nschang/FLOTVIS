{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This creates a new .h5 file with placeholders for training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "HDF5 (aka H5) is a memory mapped file formats. The Python package h5py makes it easy to store and manipulate existing data in the form of NumPy arrays. This makes reading data on Colab faster, and will accelerate the training."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import h5py\n",
    "from PIL import Image\n",
    "\n",
    "fileName = 'data.h5'\n",
    "numOfSamples = 10000\n",
    "with h5py.File(fileName, \"w\") as out:\n",
    "  out.create_dataset(\"X_train\",(numOfSamples,256,256,3),dtype='u1')\n",
    "  out.create_dataset(\"Y_train\",(numOfSamples,1,1),dtype='u1')      \n",
    "  out.create_dataset(\"X_dev\",(numOfSamples,256,256,3),dtype='u1')\n",
    "  out.create_dataset(\"Y_dev\",(numOfSamples,1,1),dtype='u1')      \n",
    "  out.create_dataset(\"X_test\",(numOfSamples,256,256,3),dtype='u1')\n",
    "  out.create_dataset(\"Y_test\",(numOfSamples,1,1),dtype='u1')   "
   ],
   "outputs": [],
   "metadata": {
    "id": "VvMk2TqlHOZp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "load your data into these placeholders in a Python dictionary style. Here we load images to our X_train placeholder."
   ],
   "metadata": {
    "id": "JX7WK6-bH0WM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with h5py.File(fileName, \"a\") as out:\n",
    "   img = Image.open(\"X_train_1.jpg\")      # X_train_1.jpg is 256 x 256 RGB image\n",
    "   out['X_train'] = numpy.asarray(img)"
   ],
   "outputs": [],
   "metadata": {
    "id": "Xe5r9O7THxpM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For PyTorch (not relevant here but good to know), you will have to write your own .h5 Dataset that will be used by PyTorch DataLoader."
   ],
   "metadata": {
    "id": "P3BpKkrwH-Gl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "import h5py\n",
    " \n",
    "class dataset_h5(torch.utils.data.Dataset):\n",
    "    def __init__(self, in_file, transform=None):\n",
    "        super(dataset_h5, self).__init__()\n",
    " \n",
    "        self.file = h5py.File(in_file, 'r')\n",
    "        self.transform = transform\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        x = self.file['X_train'][index, ...]\n",
    "        y = self.file['Y_train'][index, ...]\n",
    "        \n",
    "        # Preprocessing each image\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)        \n",
    "        \n",
    "        return (x, y), index\n",
    " \n",
    "    def __len__(self):\n",
    "        return self.file['X_train'].shape[0]\n",
    "\n",
    "dataset = dataset_h5(\"PATH_TO_YOUR_.h5_FILE\",transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=8,\n",
    "        drop_last=True, shuffle=bshuffle, num_workers=1)"
   ],
   "outputs": [],
   "metadata": {
    "id": "FtI_jcDAH9H7"
   }
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}